{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ETL Process with PostgreSQL and Python**  \n",
    "##### **Written by: Liseth Esmeralda Erazo Varela**  \n",
    "\n",
    "In this section, we will set up an **ETL (Extract, Transform, Load) pipeline** using **PostgreSQL** and **Python**.  \n",
    "The goal is to efficiently load raw data, perform necessary **data cleaning** and **transformations**, and store the processed data in a structured format for analysis.  \n",
    "\n",
    "##### **Steps in this process:**  \n",
    "- Establish a **connection to PostgreSQL** from Python.  \n",
    "- Load **raw data** into a dedicated staging table.  \n",
    "- Perform **data cleaning and transformations** to ensure data integrity.  \n",
    "- Store the **cleaned dataset** in a final table for further analysis.  \n",
    "- Prepare the data for **visualization** in a dashboard.  \n",
    "\n",
    "By structuring the ETL pipeline this way, we ensure that the process is **efficient, scalable, and reproducible** for future use. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, chargue the credentials for the database. I put a print in config to dettect anomalies in the connection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'postgres', 'password': '12345', 'host': 'localhost', 'port': 5432}\n"
     ]
    }
   ],
   "source": [
    "with open(\"credenciales.json\", \"r\", encoding=\"utf-8\") as config_file:\n",
    "     config = json.load(config_file)\n",
    "print (config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the connection with PostgreSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conexi√≥n exitosa a PostgreSQL - PostgreSQL 17.4 on x86_64-windows, compiled by msvc-19.42.34436, 64-bit\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(**config)\n",
    "    cursor = conn.cursor()\n",
    "    conn.autocommit = True \n",
    "    \n",
    "   \n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    db_version = cursor.fetchone()\n",
    "    print(f\"‚úÖ Conexi√≥n exitosa a PostgreSQL - {db_version[0]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error en la conexi√≥n: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create the Database. The database will be used to store the raw data before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al crear la base de datos: la base de datos ¬´candidatos¬ª ya existe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cursor.execute(\"CREATE DATABASE candidatos;\")\n",
    "    print(\"Base de datos 'candidatos' creada.\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error al crear la base de datos: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the connection to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Conexi√≥n cerrada.\n"
     ]
    }
   ],
   "source": [
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"üîó Conexi√≥n cerrada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after, open again the connection, connect to the database and create the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conectado a la base de datos: candidatos\n"
     ]
    }
   ],
   "source": [
    "config[\"dbname\"] = \"candidatos\"  \n",
    "conn = psycopg2.connect(**config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "cursor.execute(\"SELECT current_database();\")\n",
    "db_name = cursor.fetchone()[0]\n",
    "print(f\"‚úÖ Conectado a la base de datos: {db_name}\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the table for dirty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al crear la tabla: la relaci√≥n ¬´aplicantes¬ª ya existe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with psycopg2.connect(**config) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            create_table_query = \"\"\"\n",
    "            CREATE TABLE aplicantes (\n",
    "                first_name TEXT NOT NULL,\n",
    "                last_name TEXT NOT NULL,\n",
    "                email TEXT NOT NULL,\n",
    "                application_date DATE NOT NULL,\n",
    "                country TEXT NOT NULL,\n",
    "                years_of_experience INT,\n",
    "                seniority TEXT NOT NULL,\n",
    "                technology TEXT NOT NULL,\n",
    "                code_challenge_score NUMERIC,\n",
    "                technical_interview_score NUMERIC\n",
    "            );\n",
    "            \"\"\"\n",
    "            cursor.execute(create_table_query)\n",
    "            conn.commit()\n",
    "            print(\"Tabla 'aplicantes' creada.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al crear la tabla: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charge the data. you should have the data in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo subido exitosamente a PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"your_path_here.csv\"\n",
    "try:\n",
    "    with psycopg2.connect(**config) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            with open(csv_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                cursor.copy_expert(\"\"\"\n",
    "                COPY aplicantes FROM STDIN WITH CSV HEADER DELIMITER ';';\n",
    "                \"\"\", file)\n",
    "            \n",
    "            conn.commit()\n",
    "            print(\"Archivo subido exitosamente a PostgreSQL.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al subir el archivo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memer\\AppData\\Local\\Temp\\ipykernel_18340\\1254966727.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first_name   last_name                      email application_date  \\\n",
      "0  Bernadette   Langworth        leonard91@yahoo.com       2021-02-26   \n",
      "1      Camryn    Reynolds        zelda56@hotmail.com       2021-09-09   \n",
      "2       Larue      Spinka   okey_schultz41@gmail.com       2020-04-14   \n",
      "3        Arch      Spinka     elvera_kulas@yahoo.com       2020-10-01   \n",
      "4       Larue  Altenwerth  minnie.gislason@gmail.com       2020-05-20   \n",
      "\n",
      "   country  years_of_experience  seniority                         technology  \\\n",
      "0   Norway                    2     Intern                      Data Engineer   \n",
      "1   Panama                   10     Intern                      Data Engineer   \n",
      "2  Belarus                    4  Mid-Level                     Client Success   \n",
      "3  Eritrea                   25    Trainee                          QA Manual   \n",
      "4  Myanmar                   13  Mid-Level  Social Media Community Management   \n",
      "\n",
      "   code_challenge_score  technical_interview_score  \n",
      "0                   3.0                        3.0  \n",
      "1                   2.0                       10.0  \n",
      "2                  10.0                        9.0  \n",
      "3                   7.0                        1.0  \n",
      "4                   9.0                        7.0  \n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(**config)\n",
    "\n",
    "query = \"SELECT * FROM aplicantes;\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the function .info help us to get more information about the dataset. The fuction could be used when you first load a dataset to get a quick overview. also to check missing data or incorrect data types and to understand the structure of the DataFrame before performing further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   first_name                 100000 non-null  object \n",
      " 1   last_name                  100000 non-null  object \n",
      " 2   email                      100000 non-null  object \n",
      " 3   application_date           100000 non-null  object \n",
      " 4   country                    100000 non-null  object \n",
      " 5   years_of_experience        100000 non-null  int64  \n",
      " 6   seniority                  100000 non-null  object \n",
      " 7   technology                 100000 non-null  object \n",
      " 8   code_challenge_score       100000 non-null  float64\n",
      " 9   technical_interview_score  100000 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe fuction, for numerical columns calculates and displays some statistics like count, mean, std, min, percentile and max. For categorical columns count -> non-null values, unique -> unique categories, top -> most frequently category, freq -> Most common Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>code_challenge_score</th>\n",
       "      <th>technical_interview_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.286980</td>\n",
       "      <td>4.99640</td>\n",
       "      <td>5.003880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.830608</td>\n",
       "      <td>3.16688</td>\n",
       "      <td>3.165066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       years_of_experience  code_challenge_score  technical_interview_score\n",
       "count        100000.000000          100000.00000              100000.000000\n",
       "mean             15.286980               4.99640                   5.003880\n",
       "std               8.830608               3.16688                   3.165066\n",
       "min               0.000000               0.00000                   0.000000\n",
       "25%               8.000000               2.00000                   2.000000\n",
       "50%              15.000000               5.00000                   5.000000\n",
       "75%              23.000000               8.00000                   8.000000\n",
       "max              30.000000              10.00000                  10.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*isnull.sume()* is used to check missing values in a dataframe. isnull just returns a Dataframe with boolean values. 1 if the data is missing or 0 if the value is present. .sum just sums up the true (1) values for each column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name                   0\n",
       "last_name                    0\n",
       "email                        0\n",
       "application_date             0\n",
       "country                      0\n",
       "years_of_experience          0\n",
       "seniority                    0\n",
       "technology                   0\n",
       "code_challenge_score         0\n",
       "technical_interview_score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line of code df.duplicated().sum() is used to check for duplicate rows in a DataFrame. First of all it considers all columns when it identifies duplicates. Therefore the function .sum() count the number of true values.  The result is the total number of duplicate rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(50000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next line of the code, I wanted to see the name of each column in the Dataset. This function helps me with this because returns a list with the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_name', 'last_name', 'email', 'application_date', 'country', 'years_of_experience', 'seniority', 'technology', 'code_challenge_score', 'technical_interview_score']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential bias could be that a candidate might attempt to apply twice. Since we do not have an identification document to verify this, we will check for duplicates using their email address. We could delete the duplicates to keep only one entry, but since this is a fictional exercise, we will only write the line of code for learning purposes.\n",
    "\n",
    "The value_counts function helps us identify and analyze duplicates within the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email\n",
       "fern70@gmail.com              6\n",
       "marianne31@yahoo.com          6\n",
       "omari6@gmail.com              4\n",
       "rodolfo28@gmail.com           4\n",
       "isaiah24@yahoo.com            4\n",
       "                             ..\n",
       "rocky_mitchell@hotmail.com    2\n",
       "dolores.roob@hotmail.com      2\n",
       "savanah.stracke@gmail.com     2\n",
       "vivienne.fritsch@yahoo.com    2\n",
       "abigayle.crooks@yahoo.com     2\n",
       "Name: count, Length: 49833, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"email\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's clean the data and perform data transformations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new column in the Dataset named hired. this column help us to determinate the status of the candidate. Lets break down the code step by step:\n",
    "\n",
    "- df[\"hired\"] creates the new column. \n",
    "- now, we used the numpy library with the fuction where, that works like if-else. \n",
    "- (df[\"Code Challenge Score\"] >= 7) & (df[\"Technical Interview Score\"] >= 7) is the condition being evaluated.If the candidate's \"Code Challenge Score\" and \"Technical Interview Score\" are both 7 or higher, the value in the \"hired\" column will be True. Otherwise, the value will be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hired\"] = np.where((df[\"code_challenge_score\"] >= 7) & (df[\"technical_interview_score\"] >= 7), True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to identify the best candidates based on their scores. To do this, I will create a function that evaluates each candidate's performance in the areas Code Challenge Score and Technical Interview Score. If the candidate's areas are both 7 or higher, the fuction sums the score. if the candidate's \"Code Challenge Score\" or \"Technical  Interview Score\" are less than 7, the score will be 0. This way, only candidates who meet the minimum requirements in both areas will have a positive score, and I can easily identify the best candidates based on their total scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cts(row): #Cts = calculate total score.\n",
    "    if row[\"code_challenge_score\"] >= 7 and row[\"technical_interview_score\"] >= 7:\n",
    "        return row[\"code_challenge_score\"] + row[\"technical_interview_score\"]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the column Total Score for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_score\"] = df.apply(Cts, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame by \"Total Score\" in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"total_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hired\" column currently contains boolean values (True/False).  \n",
    "For better analysis and integration into a database, it is converted into an integer format (1 for hired, 0 for not hired).  \n",
    "This transformation allows for easier aggregations and statistical calculations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hired\"] = df[\"hired\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the dataset by \"Country\" and summing the \"hired\" column allows us to determine how many candidates were hired in each country.  \n",
    "Sorting the results in descending order helps identify which countries have the highest hiring rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               country  hired\n",
      "160           Northern Mariana Islands     88\n",
      "93   Heard Island and McDonald Islands     82\n",
      "156                              Niger     80\n",
      "204                          Sri Lanka     80\n",
      "194                         Seychelles     80\n",
      "..                                 ...    ...\n",
      "37                              Canada     36\n",
      "187   Saint Vincent and the Grenadines     32\n",
      "130                           Maldives     32\n",
      "86                                Guam     30\n",
      "143                         Montenegro     30\n",
      "\n",
      "[244 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "hires_by_country = df.groupby(\"country\")[\"hired\"].sum().reset_index()\n",
    "hires_by_country = hires_by_country.sort_values(by=\"hired\", ascending=False)\n",
    "print (hires_by_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before categorizing, we first inspect the distinct values in this column to understand the range of technologies present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Client Success' 'Data Engineer' 'Development - Frontend'\n",
      " 'Social Media Community Management' 'Development - Backend'\n",
      " 'Technical Writing' 'Design' 'Business Intelligence'\n",
      " 'Development - CMS Backend' 'Security' 'Development - CMS Frontend'\n",
      " 'Salesforce' 'QA Manual' 'Mulesoft' 'Database Administration'\n",
      " 'Adobe Experience Manager' 'Game Development' 'Security Compliance'\n",
      " 'DevOps' 'Business Analytics / Project Management' 'QA Automation'\n",
      " 'System Administration' 'Development - FullStack' 'Sales']\n"
     ]
    }
   ],
   "source": [
    "print(df['technology'].unique()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the analysis in Power BI, we consolidate the various technologies into seven main categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_category\n",
      "Other Areas                        26960\n",
      "Backend & FullStack Development    23198\n",
      "Infrastructure & Security          19220\n",
      "Databases & Data Science            7768\n",
      "Frontend Development                7642\n",
      "Data Analysis & BI                  7624\n",
      "QA & Testing                        7588\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para mapear tecnolog√≠as a categor√≠as generales (7 categor√≠as)\n",
    "tech_categories = {\n",
    "    'Development - Frontend': 'Frontend Development',\n",
    "    'Development - CMS Frontend': 'Frontend Development',\n",
    "\n",
    "    'Development - Backend': 'Backend & FullStack Development',\n",
    "    'Development - FullStack': 'Backend & FullStack Development',\n",
    "    'Development - CMS Backend': 'Backend & FullStack Development',\n",
    "    'Game Development': 'Backend & FullStack Development',\n",
    "    'Mulesoft': 'Backend & FullStack Development',\n",
    "\n",
    "    'DevOps': 'Infrastructure & Security',\n",
    "    'System Administration': 'Infrastructure & Security',\n",
    "    'Security': 'Infrastructure & Security',\n",
    "    'Security Compliance': 'Infrastructure & Security',\n",
    "\n",
    "    'Database Administration': 'Databases & Data Science',\n",
    "    'Data Engineer': 'Databases & Data Science',\n",
    "\n",
    "    'Business Intelligence': 'Data Analysis & BI',\n",
    "    'Business Analytics / Project Management': 'Data Analysis & BI',\n",
    "\n",
    "    'QA Manual': 'QA & Testing',\n",
    "    'QA Automation': 'QA & Testing',\n",
    "\n",
    "    'Salesforce': 'Other Areas',\n",
    "    'Adobe Experience Manager': 'Other Areas',\n",
    "    'Technical Writing': 'Other Areas',\n",
    "    'Social Media Community Management': 'Other Areas',\n",
    "    'Design': 'Other Areas',\n",
    "    'Client Success': 'Other Areas',\n",
    "    'Sales': 'Other Areas'\n",
    "}\n",
    "\n",
    "# Crear la nueva columna con la categor√≠a ajustada\n",
    "df['tech_category'] = df['technology'].map(tech_categories)\n",
    "\n",
    "# Verificar la distribuci√≥n\n",
    "print(df['tech_category'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets see the dataframe cleaned in python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>application_date</th>\n",
       "      <th>country</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>seniority</th>\n",
       "      <th>technology</th>\n",
       "      <th>code_challenge_score</th>\n",
       "      <th>technical_interview_score</th>\n",
       "      <th>hired</th>\n",
       "      <th>total_score</th>\n",
       "      <th>tech_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42366</th>\n",
       "      <td>Cyril</td>\n",
       "      <td>Larson</td>\n",
       "      <td>ray91@hotmail.com</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>2</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Client Success</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other Areas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19338</th>\n",
       "      <td>Caleb</td>\n",
       "      <td>Stehr</td>\n",
       "      <td>vicenta.williamson@yahoo.com</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>15</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Databases &amp; Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9066</th>\n",
       "      <td>Fletcher</td>\n",
       "      <td>Macejkovic</td>\n",
       "      <td>savanna11@gmail.com</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>15</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Development - Frontend</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Frontend Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70066</th>\n",
       "      <td>Devonte</td>\n",
       "      <td>Boyle</td>\n",
       "      <td>madisen9@hotmail.com</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>22</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Social Media Community Management</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other Areas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41762</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>Yost</td>\n",
       "      <td>savannah_walter50@gmail.com</td>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>Cape Verde</td>\n",
       "      <td>26</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Development - Backend</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Backend &amp; FullStack Development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first_name   last_name                         email application_date  \\\n",
       "42366      Cyril      Larson             ray91@hotmail.com       2018-06-30   \n",
       "19338      Caleb       Stehr  vicenta.williamson@yahoo.com       2021-10-20   \n",
       "9066    Fletcher  Macejkovic           savanna11@gmail.com       2020-07-17   \n",
       "70066    Devonte       Boyle          madisen9@hotmail.com       2020-12-15   \n",
       "41762    Carroll        Yost   savannah_walter50@gmail.com       2018-04-26   \n",
       "\n",
       "                        country  years_of_experience  seniority  \\\n",
       "42366                Madagascar                    2     Junior   \n",
       "19338                 Hong Kong                   15     Senior   \n",
       "9066   Central African Republic                   15  Mid-Level   \n",
       "70066                 Sri Lanka                   22     Intern   \n",
       "41762                Cape Verde                   26     Intern   \n",
       "\n",
       "                              technology  code_challenge_score  \\\n",
       "42366                     Client Success                  10.0   \n",
       "19338                      Data Engineer                  10.0   \n",
       "9066              Development - Frontend                  10.0   \n",
       "70066  Social Media Community Management                  10.0   \n",
       "41762              Development - Backend                  10.0   \n",
       "\n",
       "       technical_interview_score  hired  total_score  \\\n",
       "42366                       10.0      1         20.0   \n",
       "19338                       10.0      1         20.0   \n",
       "9066                        10.0      1         20.0   \n",
       "70066                       10.0      1         20.0   \n",
       "41762                       10.0      1         20.0   \n",
       "\n",
       "                         tech_category  \n",
       "42366                      Other Areas  \n",
       "19338         Databases & Data Science  \n",
       "9066              Frontend Development  \n",
       "70066                      Other Areas  \n",
       "41762  Backend & FullStack Development  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new table to put the cleaned data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tabla 'clean_applicants' creada correctamente.\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(**config)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "with conn.cursor() as cursor:\n",
    "    create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS aplicantes_limpios (\n",
    "            id SERIAL PRIMARY KEY,  -- ID √∫nico autoincremental\n",
    "            first_name TEXT,\n",
    "            last_name TEXT,\n",
    "            email TEXT UNIQUE,\n",
    "            application_date DATE,  -- Convertimos la fecha a DATE en PostgreSQL\n",
    "            country TEXT,\n",
    "            years_of_experience INT,\n",
    "            seniority TEXT,\n",
    "            technology TEXT,\n",
    "            code_challenge_score FLOAT,\n",
    "            technical_interview_score FLOAT,\n",
    "            hired INT,  -- Convertimos el booleano en entero\n",
    "            total_score FLOAT\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Ejecutar la consulta\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Cerrar conexi√≥n\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\" Tabla 'clean_applicants' creada correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, put the cleaned data into the table Aplicantes_limpios. we use the command engine to create the connection because it is required if im going to use the command \".to_sql()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexi√≥n exitosa a la base de datos 'candidatos' \n"
     ]
    }
   ],
   "source": [
    "# Cargar credenciales desde JSON\n",
    "with open(\"credenciales.json\") as f:\n",
    "    creds = json.load(f)\n",
    "\n",
    "# Construir la URL de conexi√≥n a la base de datos 'candidatos'\n",
    "db_url = f\"postgresql://{creds['user']}:{creds['password']}@{creds['host']}:{creds['port']}/candidatos\"\n",
    "\n",
    "# Crear el engine\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Probar la conexi√≥n\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Conexi√≥n exitosa a la base de datos 'candidatos' \")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the DataFrame into the Table (Finally!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\"clean_applicants\", con=engine, if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the data loaded successfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>application_date</th>\n",
       "      <th>country</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>seniority</th>\n",
       "      <th>technology</th>\n",
       "      <th>code_challenge_score</th>\n",
       "      <th>technical_interview_score</th>\n",
       "      <th>hired</th>\n",
       "      <th>total_score</th>\n",
       "      <th>tech_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cyril</td>\n",
       "      <td>Larson</td>\n",
       "      <td>ray91@hotmail.com</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>2</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Client Success</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other Areas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caleb</td>\n",
       "      <td>Stehr</td>\n",
       "      <td>vicenta.williamson@yahoo.com</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>15</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Databases &amp; Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fletcher</td>\n",
       "      <td>Macejkovic</td>\n",
       "      <td>savanna11@gmail.com</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>15</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Development - Frontend</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Frontend Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devonte</td>\n",
       "      <td>Boyle</td>\n",
       "      <td>madisen9@hotmail.com</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>22</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Social Media Community Management</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Other Areas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>Yost</td>\n",
       "      <td>savannah_walter50@gmail.com</td>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>Cape Verde</td>\n",
       "      <td>26</td>\n",
       "      <td>Intern</td>\n",
       "      <td>Development - Backend</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Backend &amp; FullStack Development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name   last_name                         email application_date  \\\n",
       "0      Cyril      Larson             ray91@hotmail.com       2018-06-30   \n",
       "1      Caleb       Stehr  vicenta.williamson@yahoo.com       2021-10-20   \n",
       "2   Fletcher  Macejkovic           savanna11@gmail.com       2020-07-17   \n",
       "3    Devonte       Boyle          madisen9@hotmail.com       2020-12-15   \n",
       "4    Carroll        Yost   savannah_walter50@gmail.com       2018-04-26   \n",
       "\n",
       "                    country  years_of_experience  seniority  \\\n",
       "0                Madagascar                    2     Junior   \n",
       "1                 Hong Kong                   15     Senior   \n",
       "2  Central African Republic                   15  Mid-Level   \n",
       "3                 Sri Lanka                   22     Intern   \n",
       "4                Cape Verde                   26     Intern   \n",
       "\n",
       "                          technology  code_challenge_score  \\\n",
       "0                     Client Success                  10.0   \n",
       "1                      Data Engineer                  10.0   \n",
       "2             Development - Frontend                  10.0   \n",
       "3  Social Media Community Management                  10.0   \n",
       "4              Development - Backend                  10.0   \n",
       "\n",
       "   technical_interview_score  hired  total_score  \\\n",
       "0                       10.0      1         20.0   \n",
       "1                       10.0      1         20.0   \n",
       "2                       10.0      1         20.0   \n",
       "3                       10.0      1         20.0   \n",
       "4                       10.0      1         20.0   \n",
       "\n",
       "                     tech_category  \n",
       "0                      Other Areas  \n",
       "1         Databases & Data Science  \n",
       "2             Frontend Development  \n",
       "3                      Other Areas  \n",
       "4  Backend & FullStack Development  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT * FROM clean_applicants LIMIT 5;\"\n",
    "df_preview = pd.read_sql(query, con=engine)\n",
    "df_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datachallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
